# Guide de d√©marrage - Pipeline ETL Airflow

## üìã Pr√©requis

- Docker Desktop install√© et lanc√©
- 4 GB de RAM minimum disponible

## üöÄ Installation en 5 √©tapes

### √âtape 1 : Cr√©er la structure des dossiers

```bash
# Cr√©er le dossier du projet
mkdir etl-airflow-project
cd etl-airflow-project

# Cr√©er tous les sous-dossiers
mkdir -p dags scripts data/input data/output logs plugins
```

### √âtape 2 : Cr√©er les fichiers

Cr√©ez les fichiers suivants dans leurs dossiers respectifs :

1. **dags/etl_excel_pipeline.py** ‚Üí Le DAG Airflow
2. **scripts/transform_excel.py** ‚Üí Le script de transformation
3. **docker-compose.yml** ‚Üí Configuration Docker
4. **requirements.txt** ‚Üí D√©pendances Python

### √âtape 3 : Configurer l'environnement

```bash
# Cr√©er le fichier .env
echo -e "AIRFLOW_UID=$(id -u)" > .env
```

### √âtape 4 : Installer les d√©pendances dans l'image Docker

Cr√©ez un fichier `Dockerfile` :

```dockerfile
FROM apache/airflow:2.7.1-python3.11

COPY requirements.txt /requirements.txt
RUN pip install --no-cache-dir -r /requirements.txt
```

Modifiez le `docker-compose.yml` pour utiliser cette image :

```yaml
# Remplacer la ligne "image: apache/airflow:2.7.1-python3.11" par:
build: .
```

### √âtape 5 : D√©marrer Airflow

```bash
# Construire l'image
docker-compose build

# Initialiser la base de donn√©es
docker-compose up airflow-init

# D√©marrer tous les services
docker-compose up -d
```

## üéØ Utilisation

### Acc√©der √† l'interface Airflow

1. Ouvrez votre navigateur : http://localhost:8080
2. Identifiants par d√©faut :
   - **Username:** airflow
   - **Password:** airflow

### Traiter un fichier Excel

1. Copiez votre fichier Excel dans le dossier `data/input/` :
   ```bash
   cp mon_fichier.xlsx data/input/
   ```

2. Dans l'interface Airflow :
   - Trouvez le DAG `etl_excel_grand_livre`
   - Activez-le (toggle sur ON)
   - Le pipeline se lance automatiquement toutes les 5 minutes

3. V√©rifiez les r√©sultats dans `data/output/` :
   - Un fichier `.json` (donn√©es structur√©es)
   - Un fichier `.xlsx` (donn√©es en tableau)

### Suivre l'ex√©cution

Dans l'interface Airflow :
- Cliquez sur le DAG `etl_excel_grand_livre`
- Onglet **Graph** : voir le workflow
- Cliquez sur une t√¢che ‚Üí **Logs** pour voir les d√©tails

## üìä Voir les logs en temps r√©el

```bash
# Logs du scheduler
docker-compose logs -f airflow-scheduler

# Logs du webserver
docker-compose logs -f airflow-webserver
```

## üõë Arr√™ter le projet

```bash
# Arr√™ter tous les services
docker-compose down

# Arr√™ter ET supprimer les donn√©es (attention!)
docker-compose down -v
```

## üîß D√©pannage

### Le DAG n'appara√Æt pas

```bash
# V√©rifier les logs du scheduler
docker-compose logs airflow-scheduler

# V√©rifier que le fichier DAG est bien pr√©sent
ls -la dags/
```

### Erreur de permissions

```bash
# Recr√©er le fichier .env avec le bon UID
echo -e "AIRFLOW_UID=$(id -u)" > .env
docker-compose down
docker-compose up airflow-init
docker-compose up -d
```

### Le fichier n'est pas trait√©

1. V√©rifiez que le fichier est bien dans `data/input/`
2. V√©rifiez que le DAG est activ√© (toggle ON)
3. Consultez les logs de la t√¢che dans l'interface Airflow

## üìù Structure des fichiers de sortie

### Fichier JSON
```json
[
  {
    "Numero_Compte": "512000",
    "Libelle_Compte": "Banque",
    "Periode": "202412",
    "Transactions": [
      {
        "Date_GL": "31/12/2024",
        "Entite": "ENVOL",
        "Compte": "512000",
        "Date": "01/12/2024",
        "Code_Journal": "BQ",
        "Numero_Piece": "001",
        "Libelle_Ecriture": "Virement",
        "Debit": 1000.0,
        "Credit": 0.0,
        "Solde": 1000.0
      }
    ]
  }
]
```

### Fichier Excel
Tableau avec colonnes :
- Numero_Compte
- Libelle_Compte  
- Periode
- Date_GL
- Entite
- Compte
- Date
- Code_Journal
- Numero_Piece
- Libelle_Ecriture
- Debit
- Credit
- Solde

## ‚è∞ Modifier la fr√©quence d'ex√©cution

Dans `dags/etl_excel_pipeline.py`, changez `schedule_interval` :

```python
# Toutes les 5 minutes (d√©faut)
schedule_interval='*/5 * * * *'

# Toutes les heures
schedule_interval='0 * * * *'

# Tous les jours √† 9h
schedule_interval='0 9 * * *'

# Manuel uniquement
schedule_interval=None
```

## üéì Commandes utiles

```bash
# Red√©marrer un service sp√©cifique
docker-compose restart airflow-scheduler

# Voir tous les conteneurs
docker-compose ps

# Entrer dans le conteneur webserver
docker-compose exec airflow-webserver bash

# Nettoyer les logs
rm -rf logs/*
```